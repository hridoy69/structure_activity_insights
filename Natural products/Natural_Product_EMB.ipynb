{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ce33d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abir1\\anaconda3\\Lib\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file...\n",
      "\n",
      "Found 4076 SMILES strings to process...\n",
      "Loading ChemBERTa model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abir1\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings...\n",
      "Processed 100/4076 molecules...\n",
      "Processed 200/4076 molecules...\n",
      "Processed 300/4076 molecules...\n",
      "Processed 400/4076 molecules...\n",
      "Processed 500/4076 molecules...\n",
      "Processed 600/4076 molecules...\n",
      "Processed 700/4076 molecules...\n",
      "Processed 800/4076 molecules...\n",
      "Processed 900/4076 molecules...\n",
      "Processed 1000/4076 molecules...\n",
      "Processed 1100/4076 molecules...\n",
      "Processed 1200/4076 molecules...\n",
      "Processed 1300/4076 molecules...\n",
      "Processed 1400/4076 molecules...\n",
      "Processed 1500/4076 molecules...\n",
      "Processed 1600/4076 molecules...\n",
      "Processed 1700/4076 molecules...\n",
      "Processed 1800/4076 molecules...\n",
      "Processed 1900/4076 molecules...\n",
      "Processed 2000/4076 molecules...\n",
      "Processed 2100/4076 molecules...\n",
      "Processed 2200/4076 molecules...\n",
      "Processed 2300/4076 molecules...\n",
      "Processed 2400/4076 molecules...\n",
      "Processed 2500/4076 molecules...\n",
      "Processed 2600/4076 molecules...\n",
      "Processed 2700/4076 molecules...\n",
      "Processed 2800/4076 molecules...\n",
      "Processed 2900/4076 molecules...\n",
      "Processed 3000/4076 molecules...\n",
      "Processed 3100/4076 molecules...\n",
      "Processed 3200/4076 molecules...\n",
      "Processed 3300/4076 molecules...\n",
      "Processed 3400/4076 molecules...\n",
      "Processed 3500/4076 molecules...\n",
      "Processed 3600/4076 molecules...\n",
      "Processed 3700/4076 molecules...\n",
      "Processed 3800/4076 molecules...\n",
      "Processed 3900/4076 molecules...\n",
      "Processed 4000/4076 molecules...\n",
      "\n",
      "Converting to numpy array...\n",
      "\n",
      "Embeddings before normalization:\n",
      "Shape: (4076, 768)\n",
      "Min value: -5.026611328125\n",
      "Max value: 5.140344142913818\n",
      "Mean value: -0.00014751325943507254\n",
      "\n",
      "Normalizing embeddings...\n",
      "\n",
      "Verifying normalization:\n",
      "Minimum value: 0.0\n",
      "Maximum value: 1.0000001192092896\n",
      "\n",
      "Creating embedding DataFrame...\n",
      "\n",
      "Saving results to C:\\Users\\abir1\\OneDrive\\Desktop\\Natural Product\\Natural_EMB.csv...\n",
      "\n",
      "Final statistics:\n",
      "Original dataframe shape: (4076, 3)\n",
      "Embedding dataframe shape: (4076, 768)\n",
      "Final dataframe shape: (4076, 771)\n",
      "\n",
      "Processing completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def normalize_embeddings(embeddings_array):\n",
    "    \"\"\"\n",
    "    Normalize embeddings to range [0,1] using Min-Max scaling\n",
    "    \n",
    "    Parameters:\n",
    "    embeddings_array (numpy.ndarray): Array of embeddings to normalize\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Normalized embeddings matrix\n",
    "    \"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_embeddings = scaler.fit_transform(embeddings_array)\n",
    "    \n",
    "    # Verify normalization\n",
    "    print(\"\\nVerifying normalization:\")\n",
    "    print(f\"Minimum value: {np.min(normalized_embeddings)}\")\n",
    "    print(f\"Maximum value: {np.max(normalized_embeddings)}\")\n",
    "    \n",
    "    return normalized_embeddings\n",
    "\n",
    "def get_molecular_embeddings(smiles_list):\n",
    "    \"\"\"\n",
    "    Calculate molecular embeddings for a list of SMILES strings using ChemBERTa\n",
    "    \n",
    "    Parameters:\n",
    "    smiles_list (list): List of SMILES strings\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Normalized embeddings matrix\n",
    "    \"\"\"\n",
    "    # Load ChemBERTa model and tokenizer\n",
    "    print(\"Loading ChemBERTa model and tokenizer...\")\n",
    "    model_name = \"seyonec/ChemBERTa-zinc-base-v1\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize list to store embeddings\n",
    "    embeddings_list = []\n",
    "    \n",
    "    # Process each SMILES string\n",
    "    print(\"\\nGenerating embeddings...\")\n",
    "    with torch.no_grad():\n",
    "        for i, smiles in enumerate(smiles_list):\n",
    "            try:\n",
    "                # Tokenize SMILES\n",
    "                inputs = tokenizer(smiles, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "                \n",
    "                # Get model outputs\n",
    "                outputs = model(**inputs)\n",
    "                \n",
    "                # Use CLS token embedding (first token)\n",
    "                embedding = outputs.last_hidden_state[:, 0, :].numpy()\n",
    "                embeddings_list.append(embedding.flatten())\n",
    "                \n",
    "                # Print progress every 100 molecules\n",
    "                if (i + 1) % 100 == 0:\n",
    "                    print(f\"Processed {i + 1}/{len(smiles_list)} molecules...\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing SMILES: {smiles}\")\n",
    "                print(f\"Error message: {str(e)}\")\n",
    "                # Add a zero vector as embedding for failed cases\n",
    "                embeddings_list.append(np.zeros(768))  # ChemBERTa base model has 768 dimensions\n",
    "    \n",
    "    # Convert list to numpy array\n",
    "    print(\"\\nConverting to numpy array...\")\n",
    "    embeddings_array = np.array(embeddings_list)\n",
    "    \n",
    "    # Print shape and stats before normalization\n",
    "    print(\"\\nEmbeddings before normalization:\")\n",
    "    print(f\"Shape: {embeddings_array.shape}\")\n",
    "    print(f\"Min value: {np.min(embeddings_array)}\")\n",
    "    print(f\"Max value: {np.max(embeddings_array)}\")\n",
    "    print(f\"Mean value: {np.mean(embeddings_array)}\")\n",
    "    \n",
    "    # Normalize embeddings\n",
    "    print(\"\\nNormalizing embeddings...\")\n",
    "    normalized_embeddings = normalize_embeddings(embeddings_array)\n",
    "    \n",
    "    return normalized_embeddings\n",
    "\n",
    "def process_drug_file(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Process a CSV file containing drug SMILES and save embeddings\n",
    "    \n",
    "    Parameters:\n",
    "    input_file (str): Path to input CSV file with SMILES column\n",
    "    output_file (str): Path to save output embeddings\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Processed data with embeddings\n",
    "    \"\"\"\n",
    "    # Read the CSV file\n",
    "    print(\"Reading CSV file...\")\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    print(f\"\\nFound {len(df)} SMILES strings to process...\")\n",
    "    \n",
    "    # Check if SMILES column exists\n",
    "    if 'SMILES' not in df.columns:\n",
    "        raise KeyError(\"CSV file must contain a 'SMILES' column\")\n",
    "    \n",
    "    # Calculate embeddings\n",
    "    embeddings = get_molecular_embeddings(df['SMILES'].tolist())\n",
    "    \n",
    "    print(\"\\nCreating embedding DataFrame...\")\n",
    "    # Create DataFrame with embeddings\n",
    "    embedding_df = pd.DataFrame(\n",
    "        embeddings,\n",
    "        columns=[f'embedding_{i}' for i in range(embeddings.shape[1])]\n",
    "    )\n",
    "    \n",
    "    # Combine original data with embeddings\n",
    "    result_df = pd.concat([df, embedding_df], axis=1)\n",
    "    \n",
    "    print(f\"\\nSaving results to {output_file}...\")\n",
    "    # Save to CSV\n",
    "    result_df.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Print final statistics\n",
    "    print(\"\\nFinal statistics:\")\n",
    "    print(f\"Original dataframe shape: {df.shape}\")\n",
    "    print(f\"Embedding dataframe shape: {embedding_df.shape}\")\n",
    "    print(f\"Final dataframe shape: {result_df.shape}\")\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = r\"C:\\Users\\abir1\\OneDrive\\Desktop\\Natural Product\\Natural_test_unique.csv\"\n",
    "    output_file = r\"C:\\Users\\abir1\\OneDrive\\Desktop\\Natural Product\\Natural_EMB.csv\"\n",
    "    \n",
    "    try:\n",
    "        result = process_drug_file(input_file, output_file)\n",
    "        print(\"\\nProcessing completed successfully!\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: Input file not found. Please check the file path.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8414cf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
